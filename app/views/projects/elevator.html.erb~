<div id="project-elevator" class="panel content">
  <style>
#project-elevator .info_panel:hover
{
	height:580px;
}
    </style>
  <ul class="project-slideshow">
    <li class="selected" >
      <div></div>
      <span style='background-image: url(<%= image_path "projects/elevator/elevator-buttons.jpg" %>)'>
      </span>

    </li>
    <li>
      <div></div>
      <span>
      </span>

      <iframe class="video" src="http://player.vimeo.com/video/57355751?byline=0&amp;portrait=0" width="600" height="375" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>

    </li>

  </ul>


  <div class="info_panel">

    <div class="ip_title">
      Elevator Robot
      <div class="ip_icon">
      </div>
    </div>



    <div class="ip_content">
      <p>

	I worked with Dr. Andrew Ng, the head Stanford AI Laboratory, to develop an algorithm that would teach a robot to successfully detect, classify and push control panel buttons found in any elevator.  Our approach required processing thousands of images for training the algorithm to detect all types of elevator buttons.  Once trained, the algorithm performed sliding window object detection on an image and detected regions that were likely elevator buttons.  It then overlaid a grid on the detection data to impose floor ordering logic and combined photo character recognition and hidden Markov models to determine the floor label for each button.  We implemented the algorithm on the Stanford Artificial Intelligence Robot (STAIR) and enabled it to autonomously operate any elevator. 
      </p>

      <br>  
      <p>
	The 2010 International Conference on Robotics and Automation (ICRA) published our paper which is available <a href="http://ai.stanford.edu/~ang/papers/icra10-OperationOfNovelElevators.pdf" target="_blank"> here </a>.</p>
    </div>

  </div>

</div>
